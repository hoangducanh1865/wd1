{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ace7a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'wd1'...\n",
      "remote: Enumerating objects: 130, done.\u001b[K\n",
      "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 130 (delta 58), reused 99 (delta 41), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (130/130), 14.75 MiB | 24.55 MiB/s, done.\n",
      "Resolving deltas: 100% (58/58), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hoangducanh1865/wd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0043c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/wd1\n"
     ]
    }
   ],
   "source": [
    "%cd wd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3acdb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5df2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD is now at 1d4d1e3 feat: update paths\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git reset --hard origin/dev\n",
    "!git pull "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9152f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
      "Requirement already satisfied: bitsandbytes==0.45.3 in /usr/local/lib/python3.12/dist-packages (0.45.3)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.45.3) (2.8.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.45.3) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes==0.45.3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes==0.45.3) (3.0.3)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/trl.git@0f88c179e30b3439467942a08c3190f624d5c423\n",
      "  Cloning https://github.com/huggingface/trl.git (to revision 0f88c179e30b3439467942a08c3190f624d5c423) to /tmp/pip-req-build-qyevvqes\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-qyevvqes\n",
      "  Running command git rev-parse -q --verify 'sha^0f88c179e30b3439467942a08c3190f624d5c423'\n",
      "  Running command git fetch -q https://github.com/huggingface/trl.git 0f88c179e30b3439467942a08c3190f624d5c423\n",
      "  Running command git checkout -q 0f88c179e30b3439467942a08c3190f624d5c423\n",
      "  Resolved https://github.com/huggingface/trl.git to commit 0f88c179e30b3439467942a08c3190f624d5c423\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.16.0.dev0) (1.11.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.16.0.dev0) (4.4.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from trl==0.16.0.dev0) (14.2.0)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.16.0.dev0) (4.57.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.0->trl==0.16.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl==0.16.0.dev0) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (2025.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.16.0.dev0) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.16.0.dev0) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.16.0.dev0) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl==0.16.0.dev0) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl==0.16.0.dev0) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.34.0->trl==0.16.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.2.1rc0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=3.0.0->trl==0.16.0.dev0) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.16.0.dev0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.16.0.dev0) (2.6.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0->trl==0.16.0.dev0) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0->trl==0.16.0.dev0) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl==0.16.0.dev0) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.16.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.16.0.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl==0.16.0.dev0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.16.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->trl==0.16.0.dev0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->trl==0.16.0.dev0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.16.0.dev0) (0.1.2)\n",
      "Collecting accelerate==1.4.0\n",
      "  Using cached accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deepspeed==0.16.4\n",
      "  Using cached deepspeed-0.16.4.tar.gz (1.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting datasets==3.3.2\n",
      "  Using cached datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting wandb==0.15.3\n",
      "  Downloading wandb-0.15.3-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Collecting peft==0.15.1\n",
      "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.8.0+cu126)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.6.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (0.8.1)\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (1.1.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (1.13.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (2.12.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from deepspeed==0.16.4) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (22.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.3.2)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.32.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.6.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.3.2)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.3.2)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.13.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.12/dist-packages (from wandb==0.15.3) (8.3.1)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb==0.15.3) (3.1.45)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb==0.15.3) (2.42.1)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb==0.15.3)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pathtools (from wandb==0.15.3)\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m No available output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[31mERROR: Failed to build 'pathtools' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0mtrl version: 0.16.0.dev0\n",
      "✓ bitsandbytes version: 0.45.3\n"
     ]
    }
   ],
   "source": [
    "# First, ensure we have the base packages\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "\n",
    "!pip install bitsandbytes==0.45.3\n",
    "!pip install transformers==4.46.0\n",
    "!pip install git+https://github.com/huggingface/trl.git@0f88c179e30b3439467942a08c3190f624d5c423\n",
    "\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# Ensure critical packages are installed\n",
    "!pip install accelerate==1.4.0 deepspeed==0.16.4 datasets==3.3.2 wandb==0.15.3 pandas peft==0.15.1\n",
    "\n",
    "!python -c \"import trl; print(f'trl version: {trl.__version__}')\"\n",
    "!python -c \"import bitsandbytes; print(f'✓ bitsandbytes version: {bitsandbytes.__version__}')\"\n",
    "!python -c \"import transformers; print(f'✓ transformers version: {transformers.__version__}')\"\n",
    "\n",
    "!mkdir -p /kaggle/working/data/var_diff/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f20742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.46.0\n",
      "  Downloading transformers-4.46.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (0.6.2)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.0)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (1.2.1rc0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (2025.11.12)\n",
      "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'transformers' candidate (version 4.46.0 at https://files.pythonhosted.org/packages/db/88/1ef8a624a33d7fe460a686b9e0194a7916320fc0d67d4e38e570beeac039/transformers-4.46.0-py3-none-any.whl (from https://pypi.org/simple/transformers/) (requires-python:>=3.8.0))\n",
      "Reason for being yanked: This version unfortunately does not work with 3.8 but we did not drop the support yet\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading transformers-4.46.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.12m0/2\u001b[0m [tokenizers]\n",
      "\u001b[2K    Uninstalling transformers-4.57.1:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.20.3 transformers-4.46.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.46.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a55a9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "✓ transformers version: 4.46.0\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import transformers; print(f'✓ transformers version: {transformers.__version__}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8fc507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"BASE_DATA\"] = \"/kaggle/working/data\"\n",
    "os.environ[\"HF_HOME\"] = \"/kaggle/working/cache\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4cc0c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Detect hardware\n",
    "# gpu_count = torch.cuda.device_count()\n",
    "# print(f\"Detected {gpu_count} GPUs\")\n",
    "\n",
    "# if gpu_count == 0:\n",
    "#     print(\"WARNING: No GPUs detected.\")\n",
    "#     num_processes = 1\n",
    "# elif gpu_count == 1:\n",
    "#     print(\"Running on single GPU (P100/T4). Adjusting num_processes to 1.\")\n",
    "#     num_processes = 1\n",
    "#     name = torch.cuda.get_device_name(0)\n",
    "#     if \"P100\" in name:\n",
    "#         print(f\"Warning: Detected {name}. Consider switching to 'GPU T4 x2'.\")\n",
    "# else:\n",
    "#     print(f\"Running on {gpu_count} GPUs.\")\n",
    "#     num_processes = gpu_count\n",
    "\n",
    "# model_name = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
    "# dataset = \"countdown\"\n",
    "\n",
    "# test = True\n",
    "# if test:\n",
    "#     run_name = f\"test_light_{dataset}\"\n",
    "\n",
    "#     cmd = f\"\"\"accelerate launch --config_file kaggle/accelerate.yaml \\\\\n",
    "#         --num_processes {num_processes} \\\\\n",
    "#         --main_process_port 29500 \\\\\n",
    "#         wd1/run_train.py \\\\\n",
    "#         --config wd1/train.yaml \\\\\n",
    "#         --model_path {model_name} \\\\\n",
    "#         --num_iterations 2 \\\\\n",
    "#         --dataset {dataset} \\\\\n",
    "#         --trainer_type wll_d1_neg \\\\\n",
    "#         --run_name {run_name} \\\\\n",
    "#         --report_to none \\\\\n",
    "#         --max_steps 5 \\\\\n",
    "#         --per_device_train_batch_size 2 \\\\\n",
    "#         --gradient_accumulation_steps 1 \\\\\n",
    "#         --max_completion_length 64 \\\\\n",
    "#         --block_length 16 \\\\\n",
    "#         --diffusion_steps 16 \\\\\n",
    "#         --num_generations 2 \\\\\n",
    "#         --output_dir /kaggle/working/data/var_diff/checkpoints/{run_name}\"\"\"\n",
    "# else:\n",
    "#     run_name = f\"wll_NP_{dataset}\"\n",
    "#     cmd = f\"\"\"accelerate launch --config_file kaggle/accelerate.yaml \\\\\n",
    "#         --num_processes {num_processes} \\\\\n",
    "#         --main_process_port 29500 \\\\\n",
    "#         wd1/run_train.py \\\\\n",
    "#         --config wd1/train.yaml \\\\\n",
    "#         --model_path {model_name} \\\\\n",
    "#         --num_iterations 12 \\\\\n",
    "#         --dataset {dataset} \\\\\n",
    "#         --trainer_type wll_d1_neg \\\\\n",
    "#         --run_name {run_name} \\\\\n",
    "#         --report_to none \\\\\n",
    "#         --output_dir /kaggle/working/data/var_diff/checkpoints/{run_name}\"\"\"\n",
    "\n",
    "# !{cmd}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa6502d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 GPUs\n",
      "Running on single GPU (P100/T4). Adjusting num_processes to 1.\n",
      "Warning: Detected Tesla P100-PCIE-16GB. Consider switching to 'GPU T4 x2'.\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2026-01-07 18:58:12.934833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767812292.957520    2994 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767812292.965041    2994 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767812292.983064    2994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812292.983096    2994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812292.983100    2994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812292.983103    2994 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2026-01-07 18:58:22.475827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767812302.498612    3058 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767812302.505449    3058 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767812302.523389    3058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812302.523421    3058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812302.523425    3058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767812302.523428    3058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████████████| 6/6 [00:08<00:00,  1.39s/it]\n",
      "256 examples loaded\n",
      "evaluating 256 examples\n",
      "Trainer type is:  wll_d1_neg\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Installed CUDA version 12.5 does not match the version torch was compiled with 12.6 but since the APIs are compatible, accepting this combination\n",
      "[rank0]:W0107 18:58:47.593000 3058 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "[rank0]:W0107 18:58:47.593000 3058 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
      "Before initializing optimizer states\n",
      "MA 5.6 GB         Max_MA 5.91 GB         CA 6.08 GB         Max_CA 6 GB \n",
      "CPU Virtual Memory:  used = 5.25 GB, percent = 16.7%\n",
      "After initializing optimizer states\n",
      "MA 5.6 GB         Max_MA 5.6 GB         CA 6.08 GB         Max_CA 6 GB \n",
      "CPU Virtual Memory:  used = 5.86 GB, percent = 18.7%\n",
      "After initializing ZeRO optimizer\n",
      "MA 5.6 GB         Max_MA 5.6 GB         CA 6.08 GB         Max_CA 6 GB \n",
      "CPU Virtual Memory:  used = 5.86 GB, percent = 18.7%\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]/kaggle/working/wd1/wd1/trainers/rev_grpo_trainer.py:188: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n",
      "/kaggle/working/wd1/wd1/trainers/rev_grpo_trainer.py:220: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.args.fp16):\n",
      "--------------------------------\n",
      "Target: 99 | Numbers: [61, 17, 55]\n",
      "Extracted equation: 61 + 55  - 17\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to exactly 99 using the numbers [61, 17, 55], we need to consider the sum and the difference of the numbers. The sum of 61 and 55 is 116, which is close to 99. Subtracting 17 from 116 gives us 99. Therefore, the expression is (61+55)-17.\n",
      "</reasoning>\n",
      "<answer>\n",
      "61 + 55  - 17\n",
      "</answer>\n",
      "Correct equation: 61 + 55  - 17 = 99\n",
      "--------------------------------\n",
      "Target: 29 | Numbers: [11, 6, 37]\n",
      "Extracted equation: 37-6\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 29 using the numbers [11, 6, 37], we need to find all the sum of the numbers minus the target, i.e., 11 + 6 + 37 - 29 = 25. Now we need to form the number 25 using the numbers 11, 6, and 37. The only way to do this is by subtracting 6 from 37. \n",
      "</reasoning>\n",
      "<answer>\n",
      "37-6\n",
      "</answer>\n",
      "Invalid equation\n",
      "--------------------------------\n",
      "Target: 29 | Numbers: [11, 6, 37]\n",
      "Extracted equation: 37-11*6\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 29 using the numbers 11, 6, and 37 exactly we need to consider the operations of addition, subtraction, multiplication, and division. We can start by trying to use the numbers in combination and the operations to reach 29.\n",
      "</reasoning>\n",
      "<answer>\n",
      "37-11*6\n",
      "</answer>\n",
      "Wrong result: equation = -29, target = 29\n",
      "{'loss': -50.3611, 'grad_norm': 175.75697326660156, 'learning_rate': 3e-06, 'completion_length': 118.5, 'zero_std_ratio': 0.5, 'rewards/countdown_reward_func': 0.32500000670552254, 'reward': 0.32500000670552254, 'reward_std': 0.3181980550289154, 'epoch': 0.0}\n",
      "{'loss': -33.2857, 'grad_norm': 139.7291259765625, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -30.778, 'grad_norm': 108.00436401367188, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -51.5668, 'grad_norm': 161.0244903564453, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -33.6868, 'grad_norm': 139.39295959472656, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -31.1984, 'grad_norm': 216.5820770263672, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      " 12%|█████▎                                      | 6/50 [05:08<17:11, 23.43s/it]--------------------------------\n",
      "Target: 63 | Numbers: [10, 37, 36]\n",
      "Extracted equation: 37-10+36-16\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 63 using the numbers [10, 37, 36], we need to find out the sum of the numbers, which is 10 + 37 + 36 = 83. The target to get 63 is 83 - 63 = 20. We can we get 20 by subtracting 16 from 36 - 10.\n",
      "</reasoning>\n",
      "<answer>\n",
      "37-10+36-16\n",
      "</answer>\n",
      "Invalid equation\n",
      "--------------------------------\n",
      "Target: 63 | Numbers: [10, 37, 36]\n",
      "Extracted equation: 36+37-10\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 63 using the numbers [10, 37, 36], we need to consider the combination of operations that can result in 63. The key is to recognize that we can add 36 and 37 to get 73, and then subtract 10 from 73 to get 63. This combination ensures that each number appears exactly once and the final result evaluates to 63.\n",
      "</reasoning>\n",
      "<answer>\n",
      "36+37-10\n",
      "</answer>\n",
      "Correct equation: 36+37-10 = 63\n",
      "{'loss': 27.204, 'grad_norm': 160.39370727539062, 'learning_rate': 3e-06, 'completion_length': 125.5, 'zero_std_ratio': 0.0, 'rewards/countdown_reward_func': 0.550000011920929, 'reward': 0.550000011920929, 'reward_std': 0.6363961100578308, 'epoch': 0.0}\n",
      "{'loss': 12.56, 'grad_norm': 207.6064453125, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 32.4261, 'grad_norm': 185.2080535888672, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 27.828, 'grad_norm': 178.772216796875, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 11.5244, 'grad_norm': 212.7153778076172, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 31.8104, 'grad_norm': 194.97805786132812, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      " 24%|██████████▎                                | 12/50 [10:16<14:48, 23.38s/it]--------------------------------\n",
      "Target: 99 | Numbers: [60, 49, 88]\n",
      "Extracted equation: 60+88-49\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to exactly 99 using the numbers [60, 49, 88], we need to consider the operations of addition, subtraction, multiplication, and division. The key is to find a way of combining these numbers to reach 99.\n",
      "</reasoning>\n",
      "<answer>\n",
      "60+88-49\n",
      "</answer>\n",
      "Correct equation: 60+88-49 = 99\n",
      "--------------------------------\n",
      "Target: 88 | Numbers: [44, 42, 2]\n",
      "Extracted equation: 44+42+2\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 88 using the numbers [44, 42, 2], we need to find a way to combine these numbers to get 88. We can see that adding 44 and 42 gives 86, which is 2 less than 88. Therefore, we need to add 2 to 86 to get 88. This means uses all numbers exactly once and uses each number exactly once.\n",
      "</reasoning>\n",
      "<answer>\n",
      "44+42+2\n",
      "</answer>\n",
      "Correct equation: 44+42+2 = 88\n",
      "--------------------------------\n",
      "Target: 88 | Numbers: [44, 42, 2]\n",
      "Extracted equation: 44+42+2\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to exactly 88 using the numbers [44, 42, 2], we need to consider the operations +, -, *, and / We can start by analyzing the numbers and trying to find a combination that adds up to 88. One way to try to combine the numbers is by using multiplication and addition operations. We can also try using subtraction and addition operations. We need also to find a way to use each number exactly once.\n",
      "</reasoning>\n",
      "<answer>\n",
      "44+42+2\n",
      "</answer>\n",
      "Correct equation: 44+42+2 = 88\n",
      "{'loss': -50.1854, 'grad_norm': 161.20164489746094, 'learning_rate': 3e-06, 'completion_length': 118.25, 'zero_std_ratio': 0.5, 'rewards/countdown_reward_func': 0.7750000059604645, 'reward': 0.7750000059604645, 'reward_std': 0.3181980550289154, 'epoch': 0.0}\n",
      "{'loss': -62.6171, 'grad_norm': 137.26522827148438, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -63.4528, 'grad_norm': 152.34295654296875, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -50.3749, 'grad_norm': 157.19052124023438, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -63.4739, 'grad_norm': 143.22116088867188, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': -63.9709, 'grad_norm': 185.672119140625, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      " 36%|███████████████▍                           | 18/50 [15:24<12:27, 23.36s/it]--------------------------------\n",
      "Target: 94 | Numbers: [99, 5, 10]\n",
      "Extracted equation: 99*10-99\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to exactly 94 using the numbers [99, 5, 10], we need to consider the properties of the numbers and the operations available. We can see that 99 and 10 = 900, which is close to 995. We can then subtract 99 from from 900 to get 94.. Therefore, the expression is 990 99.\n",
      "</reasoning>\n",
      "<answer>\n",
      "99*10-99\n",
      "</answer>\n",
      "Invalid equation\n",
      "--------------------------------\n",
      "Target: 94 | Numbers: [99, 5, 10]\n",
      "Extracted equation: 5*10 - 3 10\n",
      "Solution string: <reasoning>\n",
      "To create an arithmetic expression that evaluates to 94 using the numbers 99, 5, and 10, we need to use the operations +, -, *, and / as needed. We realize that we can multiply 5 by 10 to get 50, and then subtract 46 from 50 to get 94. Therefore, the expression is 5*10 - 3 10 = 94.\n",
      "</reasoning>\n",
      "<answer>\n",
      "5*10 - 3 10\n",
      "</answer>\n",
      "Invalid equation\n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'completion_length': 128.0, 'zero_std_ratio': 1.0, 'rewards/countdown_reward_func': 0.10000000149011612, 'reward': 0.10000000149011612, 'reward_std': 0.0, 'epoch': 0.0}\n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 3e-06, 'epoch': 0.0}           \n",
      " 50%|█████████████████████▌                     | 25/50 [24:55<39:45, 95.41s/it]\n",
      "Evaluating:   0%|                                        | 0/42 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▋                            | 1/42 [04:12<2:52:18, 252.17s/it]\u001b[A\n",
      "Evaluating:   5%|█▍                           | 2/42 [08:24<2:48:02, 252.06s/it]\u001b[A\n",
      "Evaluating:   7%|██                           | 3/42 [12:36<2:43:51, 252.09s/it]\u001b[A\n",
      "Evaluating:  10%|██▊                          | 4/42 [16:48<2:39:39, 252.10s/it]\u001b[A\n",
      "Evaluating:  12%|███▍                         | 5/42 [21:00<2:35:28, 252.12s/it]\u001b[A\n",
      "Evaluating:  14%|████▏                        | 6/42 [25:12<2:31:16, 252.12s/it]\u001b[A\n",
      "Evaluating:  17%|████▊                        | 7/42 [29:24<2:27:03, 252.10s/it]\u001b[A\n",
      "Evaluating:  19%|█████▌                       | 8/42 [33:36<2:22:49, 252.04s/it]\u001b[A\n",
      "Evaluating:  21%|██████▏                      | 9/42 [37:48<2:18:36, 252.00s/it]\u001b[A\n",
      "Evaluating:  24%|██████▋                     | 10/42 [42:00<2:14:23, 251.98s/it]\u001b[A\n",
      "Evaluating:  26%|███████▎                    | 11/42 [46:12<2:10:10, 251.96s/it]\u001b[A\n",
      "Evaluating:  29%|████████                    | 12/42 [50:24<2:05:59, 251.97s/it]\u001b[A\n",
      "Evaluating:  31%|████████▋                   | 13/42 [54:36<2:01:48, 252.02s/it]\u001b[A\n",
      "Evaluating:  33%|█████████▎                  | 14/42 [58:48<1:57:37, 252.05s/it]\u001b[A\n",
      "Evaluating:  36%|█████████▎                | 15/42 [1:03:00<1:53:26, 252.08s/it]\u001b[A\n",
      "Evaluating:  38%|█████████▉                | 16/42 [1:07:12<1:49:14, 252.10s/it]\u001b[A\n",
      "Evaluating:  40%|██████████▌               | 17/42 [1:11:25<1:45:02, 252.11s/it]\u001b[A\n",
      "Evaluating:  43%|███████████▏              | 18/42 [1:15:37<1:40:50, 252.12s/it]\u001b[A\n",
      "Evaluating:  45%|███████████▊              | 19/42 [1:19:49<1:36:39, 252.15s/it]\u001b[A\n",
      "Evaluating:  48%|████████████▍             | 20/42 [1:24:01<1:32:27, 252.15s/it]\u001b[A\n",
      "Evaluating:  50%|█████████████             | 21/42 [1:28:13<1:28:15, 252.15s/it]\u001b[A\n",
      "Evaluating:  52%|█████████████▌            | 22/42 [1:32:25<1:24:02, 252.15s/it]\u001b[A\n",
      "Evaluating:  55%|██████████████▏           | 23/42 [1:36:38<1:19:50, 252.15s/it]\u001b[A\n",
      "Evaluating:  57%|██████████████▊           | 24/42 [1:40:50<1:15:39, 252.17s/it]\u001b[A^C\n",
      "W0107 21:04:42.211000 2994 torch/distributed/elastic/agent/server/api.py:723] Received 2 death signal, shutting down workers\n",
      "W0107 21:04:42.213000 2994 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3058 closing signal SIGINT\n",
      "Evaluating:  57%|██████████████▊           | 24/42 [1:40:56<1:15:42, 252.36s/it]\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/kaggle/working/wd1/wd1/run_train.py\", line 249, in <module>\n",
      "[rank0]:     main(grpo_config=grpo_config, model_config=model_config)\n",
      "[rank0]:   File \"/kaggle/working/wd1/wd1/run_train.py\", line 243, in main\n",
      "[rank0]:     trainer.train()\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2122, in train\n",
      "[rank0]:     return inner_training_loop(\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2541, in _inner_training_loop\n",
      "[rank0]:     self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2997, in _maybe_log_save_evaluate\n",
      "[rank0]:     metrics = self._evaluate(trial, ignore_keys_for_eval)\n",
      "[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2951, in _evaluate\n",
      "[rank0]:     metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)\n",
      "[rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/kaggle/working/wd1/wd1/trainers/rev_grpo_trainer.py\", line 106, in evaluate\n",
      "[rank0]:     callback.on_evaluate(\n",
      "[rank0]:   File \"/kaggle/working/wd1/wd1/trainers/eval_callback.py\", line 183, in on_evaluate\n",
      "[rank0]:     out = generate(\n",
      "[rank0]:           ^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
      "[rank0]:     return func(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/kaggle/working/wd1/wd1/trainers/eval_callback.py\", line 106, in generate\n",
      "[rank0]:     logits = model(x).logits\n",
      "[rank0]:              ^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1879, in _call_impl\n",
      "[rank0]:     return inner()\n",
      "[rank0]:            ^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1827, in inner\n",
      "[rank0]:     result = forward_call(*args, **kwargs)\n",
      "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 1850, in forward\n",
      "[rank0]:     return self.base_model(\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n",
      "[rank0]:     return self.model.forward(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/kaggle/working/cache/modules/transformers_modules/GSAI-ML/LLaDA-8B-Instruct/08b83a6feb34df1a6011b80c3c00c7563e963b07/modeling_llada.py\", line 1431, in forward\n",
      "[rank0]:     outputs = self.model.forward(\n",
      "[rank0]:               ^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/kaggle/working/cache/modules/transformers_modules/GSAI-ML/LLaDA-8B-Instruct/08b83a6feb34df1a6011b80c3c00c7563e963b07/modeling_llada.py\", line 1328, in forward\n",
      "[rank0]:     x, cache = block(x, attention_bias=attention_bias, layer_past=layer_past, use_cache=use_cache)\n",
      "[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/kaggle/working/cache/modules/transformers_modules/GSAI-ML/LLaDA-8B-Instruct/08b83a6feb34df1a6011b80c3c00c7563e963b07/modeling_llada.py\", line 902, in forward\n",
      "[rank0]:     k = self.k_proj(x_normed)\n",
      "[rank0]:         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py\", line 480, in forward\n",
      "[rank0]:     result = self.base_layer(x, *args, **kwargs)\n",
      "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py\", line 484, in forward\n",
      "[rank0]:     return bnb.matmul_4bit(x, self.weight.t(), bias=bias, quant_state=self.weight.quant_state).to(inp_dtype)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py\", line 533, in matmul_4bit\n",
      "[rank0]:     return MatMul4Bit.apply(A, B, out, bias, quant_state)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\", line 576, in apply\n",
      "[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/autograd/_functions.py\", line 462, in forward\n",
      "[rank0]:     output = torch.nn.functional.linear(A, F.dequantize_4bit(B, quant_state).to(A.dtype).t(), bias)\n",
      "[rank0]:                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/bitsandbytes/functional.py\", line 1381, in dequantize_4bit\n",
      "[rank0]:     lib.cdequantize_blockwise_bf16_nf4(*args)\n",
      "[rank0]: KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Detect hardware\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Detected {gpu_count} GPUs\")\n",
    "\n",
    "if gpu_count == 0:\n",
    "    print(\"WARNING: No GPUs detected.\")\n",
    "    num_processes = 1\n",
    "elif gpu_count == 1:\n",
    "    print(\"Running on single GPU (P100/T4). Adjusting num_processes to 1.\")\n",
    "    num_processes = 1\n",
    "    name = torch.cuda.get_device_name(0)\n",
    "    if \"P100\" in name:\n",
    "        print(f\"Warning: Detected {name}. Consider switching to 'GPU T4 x2'.\")\n",
    "else:\n",
    "    print(f\"Running on {gpu_count} GPUs.\")\n",
    "    num_processes = gpu_count\n",
    "\n",
    "model_name = \"GSAI-ML/LLaDA-8B-Instruct\"\n",
    "dataset = \"countdown\"\n",
    "trainer_type = \"ot_wd1\" # Options: \"d1\", \"wll_d1_neg\", \"ot_wd1\"\n",
    "\n",
    "test = True\n",
    "if test:\n",
    "    run_name = f\"test_ot_{dataset}\"\n",
    "\n",
    "    cmd = f\"\"\"accelerate launch --config_file kaggle/accelerate.yaml \\\\\n",
    "        --num_processes {num_processes} \\\\\n",
    "        --main_process_port 29500 \\\\\n",
    "        wd1/run_train.py \\\\\n",
    "        --config wd1/train.yaml \\\\\n",
    "        --model_path {model_name} \\\\\n",
    "        --num_iterations 4 \\\\\n",
    "        --dataset {dataset} \\\\\n",
    "        --trainer_type {trainer_type} \\\\\n",
    "        --run_name {run_name} \\\\\n",
    "        --report_to none \\\\\n",
    "        --max_steps 50 \\\\\n",
    "        --per_device_train_batch_size 2 \\\\\n",
    "        --gradient_accumulation_steps 2 \\\\\n",
    "        --max_completion_length 128 \\\\\n",
    "        --block_length 32 \\\\\n",
    "        --diffusion_steps 32 \\\\\n",
    "        --num_generations 4 \\\\\n",
    "        --save_steps 25 \\\\\n",
    "        --eval_steps 25 \\\\\n",
    "        --output_dir /kaggle/working/data/var_diff/checkpoints/{run_name}\"\"\"\n",
    "else:\n",
    "    run_name = f\"ot_wd1_{dataset}\"\n",
    "    cmd = f\"\"\"accelerate launch --config_file kaggle/accelerate.yaml \\\\\n",
    "        --num_processes {num_processes} \\\\\n",
    "        --main_process_port 29500 \\\\\n",
    "        wd1/run_train.py \\\\\n",
    "        --config wd1/train.yaml \\\\\n",
    "        --model_path {model_name} \\\\\n",
    "        --num_iterations 12 \\\\\n",
    "        --dataset {dataset} \\\\\n",
    "        --trainer_type {trainer_type} \\\\\n",
    "        --run_name {run_name} \\\\\n",
    "        --report_to none \\\\\n",
    "        --output_dir /kaggle/working/data/var_diff/checkpoints/{run_name}\"\"\"\n",
    "\n",
    "print(f\"Running command:\\n{cmd}\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1886f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/data/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/logs/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/rng_state.pth (deflated 27%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/adapter_config.json (deflated 56%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/training_args.bin (deflated 53%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/tokenizer.json (deflated 79%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/zero_to_fp32.py (deflated 77%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/trainer_state.json (deflated 67%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/adapter_model.safetensors (deflated 24%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/special_tokens_map.json (deflated 75%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/tokenizer_config.json (deflated 96%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/README.md (deflated 65%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/latest (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/global_step5/ (stored 0%)\n",
      "  adding: kaggle/working/data/var_diff/checkpoints/test_light_countdown/checkpoint-5/global_step5/mp_rank_00_model_states.pt^C\n",
      "\n",
      "\n",
      "\n",
      "zip error: Interrupted (aborting)\n"
     ]
    }
   ],
   "source": [
    "!zip -r checkpoints_backup.zip /kaggle/working/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d33ca",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Checkpoints are saved in `/kaggle/working/data`. Download them before the session ends.\n",
    "- **P100 GPU Issue**: If you encounter CUDA compatibility errors, go to Kaggle Settings → Accelerator → Select \"GPU T4 x2\" instead of P100.\n",
    "- **Memory Issues**: If you get OOM errors, try using a smaller model like `\"Qwen/Qwen2.5-1.5B-Instruct\"` in the training cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa038b",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you're still getting import errors after installing packages:\n",
    "\n",
    "1. Restart the notebook kernel (Runtime → Restart Runtime)\n",
    "2. Re-run cells 1-5 in order\n",
    "\n",
    "If you see P100 CUDA compatibility warnings but training still starts, you can ignore them - they're just warnings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
